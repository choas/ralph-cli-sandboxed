{
  "providers": {
    "claude": {
      "name": "Claude Code",
      "description": "Anthropic's Claude Code CLI",
      "command": "claude",
      "defaultArgs": [],
      "yoloArgs": ["--dangerously-skip-permissions"],
      "promptArgs": ["-p"],
      "streamJsonArgs": ["--output-format", "stream-json", "--verbose", "--print"],
      "docker": {
        "install": "# Install Claude Code CLI (as node user so it installs to /home/node/.local/bin)\nRUN su - node -c 'curl -fsSL https://claude.ai/install.sh | bash' \\\n    && echo 'export PATH=\"$HOME/.local/bin:$PATH\"' >> /home/node/.zshrc"
      },
      "envVars": ["ANTHROPIC_API_KEY"],
      "credentialMount": "~/.claude:/home/node/.claude",
      "modelConfig": {
        "envVar": "CLAUDE_MODEL",
        "note": "Or use: ralph run --model <model>"
      },
      "modelArgs": ["--model"]
    },
    "aider": {
      "name": "Aider",
      "description": "AI pair programming in your terminal",
      "command": "aider",
      "defaultArgs": ["--yes"],
      "yoloArgs": ["--yes-always"],
      "promptArgs": ["--message"],
      "docker": {
        "install": "# Install Aider (requires Python)\nRUN apt-get update && apt-get install -y python3 python3-pip && rm -rf /var/lib/apt/lists/* \\\n    && pip3 install --break-system-packages --no-cache-dir aider-chat",
        "note": "Check 'aider --help' for available flags"
      },
      "envVars": ["OPENAI_API_KEY", "ANTHROPIC_API_KEY"],
      "credentialMount": null,
      "modelConfig": {
        "envVar": "AIDER_MODEL",
        "note": "Or use: ralph run --model <model>"
      },
      "modelArgs": ["--model"]
    },
    "codex": {
      "name": "OpenAI Codex CLI",
      "description": "OpenAI's Codex CLI for code generation",
      "command": "codex",
      "defaultArgs": ["--approval-mode", "suggest"],
      "yoloArgs": ["--approval-mode", "full-auto"],
      "promptArgs": [],
      "docker": {
        "install": "# Install OpenAI Codex CLI\nRUN npm install -g @openai/codex",
        "note": "Check 'codex --help' for available flags"
      },
      "envVars": ["OPENAI_API_KEY"],
      "credentialMount": null,
      "modelConfig": {
        "envVar": "CODEX_MODEL",
        "note": "Or use: ralph run --model <model>"
      },
      "modelArgs": ["--model"]
    },
    "gemini": {
      "name": "Gemini CLI",
      "description": "Google's Gemini CLI for code assistance",
      "command": "gemini",
      "defaultArgs": [],
      "yoloArgs": ["-y"],
      "promptArgs": [],
      "streamJsonArgs": ["--output-format", "json"],
      "docker": {
        "install": "# Install Google Gemini CLI\nRUN npm install -g @google/gemini-cli",
        "note": "Check 'gemini --help' for available flags"
      },
      "envVars": ["GEMINI_API_KEY", "GOOGLE_API_KEY"],
      "credentialMount": "~/.gemini:/home/node/.gemini",
      "modelConfig": {
        "envVar": "GEMINI_MODEL",
        "note": "Or use: ralph run --model <model>"
      },
      "modelArgs": ["--model"]
    },
    "opencode": {
      "name": "OpenCode",
      "description": "Open source AI coding agent for the terminal",
      "command": "opencode",
      "defaultArgs": [],
      "yoloArgs": ["--yolo"],
      "promptArgs": ["run"],
      "streamJsonArgs": ["--format", "json"],
      "docker": {
        "install": "# Install OpenCode (as node user)\nRUN su - node -c 'curl -fsSL https://opencode.ai/install | bash' \\\n    && echo 'export PATH=\"$HOME/.opencode/bin:$PATH\"' >> /home/node/.zshrc",
        "note": "Check 'opencode --help' for available flags"
      },
      "envVars": ["ANTHROPIC_API_KEY", "OPENAI_API_KEY", "GOOGLE_GENERATIVE_AI_API_KEY"],
      "credentialMount": null,
      "modelConfig": {
        "note": "Or use: ralph run --model <model>"
      },
      "modelArgs": ["--model"]
    },
    "amp": {
      "name": "AMP CLI",
      "description": "Sourcegraph's AMP coding agent",
      "command": "amp",
      "defaultArgs": [],
      "yoloArgs": ["--dangerously-allow-all"],
      "promptArgs": ["-x"],
      "docker": {
        "install": "# Install AMP CLI (as node user)\nRUN su - node -c 'curl -fsSL https://ampcode.com/install.sh | bash' \\\n    && echo 'export PATH=\"$HOME/.amp/bin:$PATH\"' >> /home/node/.zshrc",
        "note": "Check 'amp --help' for available flags"
      },
      "envVars": ["ANTHROPIC_API_KEY", "OPENAI_API_KEY"],
      "credentialMount": null,
      "modelConfig": {
        "note": "Or use: ralph run --model <model>"
      },
      "modelArgs": ["--model"]
    },
    "goose": {
      "name": "Goose CLI",
      "description": "Block's Goose AI coding agent",
      "command": "goose",
      "defaultArgs": [],
      "yoloArgs": [],
      "promptArgs": ["run", "--text"],
      "streamJsonArgs": ["--output-format", "stream-json"],
      "docker": {
        "install": "# Install Goose CLI (requires Python)\nRUN apt-get update && apt-get install -y python3 python3-pip python3-venv && rm -rf /var/lib/apt/lists/* \\\n    && pip3 install --break-system-packages --no-cache-dir goose-ai",
        "note": "Check 'goose --help' for available flags"
      },
      "envVars": ["OPENAI_API_KEY", "ANTHROPIC_API_KEY"],
      "credentialMount": null,
      "modelConfig": {
        "envVar": "GOOSE_PROVIDER",
        "note": "Set provider via GOOSE_PROVIDER env var"
      },
      "modelArgs": ["--model"]
    },
    "custom": {
      "name": "Custom CLI",
      "description": "Configure your own AI CLI tool",
      "command": "",
      "defaultArgs": [],
      "yoloArgs": [],
      "promptArgs": [],
      "docker": {
        "install": "# Custom CLI - add your installation commands here"
      },
      "envVars": [],
      "credentialMount": null
    }
  }
}
